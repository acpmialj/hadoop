{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac30c933-5dee-49c5-8363-6b10345e68e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sh: 0: getcwd() failed: No such file or directory\n",
      "/tmp/wordcount\n",
      "input\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Se crea el directorio de entrada\n",
    "#\n",
    "!rm -rf /tmp/wordcount\n",
    "!mkdir -p /tmp/wordcount/input\n",
    "%cd /tmp/wordcount\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97119567-5dd1-472c-ad8a-6a9e04d43943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing input/text0.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile input/text0.txt\n",
    "Analytics is the discovery, interpretation, and communication of meaningful patterns\n",
    "in data. Especially valuable in areas rich with recorded information, analytics relies\n",
    "on the simultaneous application of statistics, computer programming and operations research\n",
    "to quantify performance.\n",
    "\n",
    "Organizations may apply analytics to business data to describe, predict, and improve business\n",
    "performance. Specifically, areas within analytics include predictive analytics, prescriptive\n",
    "analytics, enterprise decision management, descriptive analytics, cognitive analytics, Big\n",
    "Data Analytics, retail analytics, store assortment and stock-keeping unit optimization,\n",
    "marketing optimization and marketing mix modeling, web analytics, call analytics, speech\n",
    "analytics, sales force sizing and optimization, price and promotion modeling, predictive\n",
    "science, credit risk analysis, and fraud analytics. Since analytics can require extensive\n",
    "computation (see big data), the algorithms and software used for analytics harness the most\n",
    "current methods in computer science, statistics, and mathematics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b3a45ab-70e3-46da-aa85-18d3fe0d7285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing input/text1.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile input/text1.txt\n",
    "The field of data analysis. Analytics often involves studying past historical data to\n",
    "research potential trends, to analyze the effects of certain decisions or events, or to\n",
    "evaluate the performance of a given tool or scenario. The goal of analytics is to improve\n",
    "the business by gaining knowledge which can be used to make improvements or changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6454fa83-7fff-4060-896e-1adea4fcf8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing input/text2.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile input/text2.txt\n",
    "Data analytics (DA) is the process of examining data sets in order to draw conclusions\n",
    "about the information they contain, increasingly with the aid of specialized systems\n",
    "and software. Data analytics technologies and techniques are widely used in commercial\n",
    "industries to enable organizations to make more-informed business decisions and by\n",
    "scientists and researchers to verify or disprove scientific models, theories and\n",
    "hypotheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d10553a7-8073-485d-a902-fe2ef18e98b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing word_counter.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile word_counter.py\n",
    "\n",
    "import string\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "\n",
    "class WordCounter(MRJob):\n",
    "    def preprocessing(self, word):\n",
    "        word = word.lower()\n",
    "        word = word.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "        word = word.replace(\"\\n\", \"\")\n",
    "        return word\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        for word in line.split():\n",
    "            word = self.preprocessing(word)\n",
    "            yield word, 1\n",
    "\n",
    "    def reducer(self, key, values):\n",
    "        yield key, sum(values)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    WordCounter.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5af9bbcc-c4e7-44dc-8ca0-f27c58ad99a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for hadoop runner\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.10.1\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.10.1.jar\n",
      "Creating temp directory /tmp/word_counter.root.20231017.085725.403752\n",
      "uploading working dir files to hdfs:///user/root/tmp/mrjob/word_counter.root.20231017.085725.403752/files/wd...\n",
      "Copying other local files to hdfs:///user/root/tmp/mrjob/word_counter.root.20231017.085725.403752/files/\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [/tmp/hadoop-unjar107615185021933938/] [] /tmp/streamjob1243160436101712810.jar tmpDir=null\n",
      "Attempting to fetch counters from logs...\n",
      "Can't fetch history log; missing job ID\n",
      "No counters found\n",
      "job output is in hdfs:///user/root/tmp/mrjob/word_counter.root.20231017.085725.403752/output\n",
      "Streaming final output from hdfs:///user/root/tmp/mrjob/word_counter.root.20231017.085725.403752/output...\n",
      "\"a\"\t1\n",
      "\"about\"\t1\n",
      "\"aid\"\t1\n",
      "\"algorithms\"\t1\n",
      "\"analysis\"\t2\n",
      "\"analytics\"\t20\n",
      "\"analyze\"\t1\n",
      "\"and\"\t15\n",
      "\"application\"\t1\n",
      "\"apply\"\t1\n",
      "Removing HDFS temp directory hdfs:///user/root/tmp/mrjob/word_counter.root.20231017.085725.403752...\n",
      "Removing temp directory /tmp/word_counter.root.20231017.085725.403752...\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Ejecución con fichero de entrada local y salida por STDOUT\n",
    "# Mrjob copia a ficheros temporales en HDFS\n",
    "# \n",
    "!python3 word_counter.py -r hadoop input/*.txt | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5be56ae4-e1eb-40a6-ac50-fb24a7bc74b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--   1 root supergroup       1082 2023-10-17 08:38 input/text0.txt\r\n",
      "-rw-r--r--   1 root supergroup        349 2023-10-17 08:38 input/text1.txt\r\n",
      "-rw-r--r--   1 root supergroup        435 2023-10-17 08:38 input/text2.txt\r\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -mkdir input\n",
    "!hadoop fs -copyFromLocal input/* input\n",
    "!hadoop fs -ls input/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0084e6d4-5c80-4e74-89fe-6ecca6bdc68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for hadoop runner\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.10.1\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.10.1.jar\n",
      "Creating temp directory /tmp/word_counter.root.20231017.085906.716125\n",
      "uploading working dir files to hdfs:///user/root/tmp/mrjob/word_counter.root.20231017.085906.716125/files/wd...\n",
      "Copying other local files to hdfs:///user/root/tmp/mrjob/word_counter.root.20231017.085906.716125/files/\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [/tmp/hadoop-unjar7399161256473237367/] [] /tmp/streamjob2536774140297239250.jar tmpDir=null\n",
      "Attempting to fetch counters from logs...\n",
      "Can't fetch history log; missing job ID\n",
      "No counters found\n",
      "job output is in hdfs:///user/root/tmp/mrjob/word_counter.root.20231017.085906.716125/output\n",
      "Streaming final output from hdfs:///user/root/tmp/mrjob/word_counter.root.20231017.085906.716125/output...\n",
      "\"a\"\t1\n",
      "\"about\"\t1\n",
      "\"aid\"\t1\n",
      "\"algorithms\"\t1\n",
      "\"analysis\"\t2\n",
      "\"analytics\"\t20\n",
      "\"analyze\"\t1\n",
      "\"and\"\t15\n",
      "\"application\"\t1\n",
      "\"apply\"\t1\n",
      "Removing HDFS temp directory hdfs:///user/root/tmp/mrjob/word_counter.root.20231017.085906.716125...\n",
      "Removing temp directory /tmp/word_counter.root.20231017.085906.716125...\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Ejecución con fichero de entrada en HDFS y salida por STDOUT\n",
    "# \n",
    "!python3 word_counter.py -r hadoop hdfs:///user/root/input | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5de5175e-af98-49b0-9acf-afbffdb9f6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted output\n",
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for hadoop runner\n",
      "Looking for hadoop binary in /opt/hadoop/bin...\n",
      "Found hadoop binary: /opt/hadoop/bin/hadoop\n",
      "Using Hadoop version 2.10.1\n",
      "Looking for Hadoop streaming jar in /opt/hadoop...\n",
      "Found Hadoop streaming jar: /opt/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.10.1.jar\n",
      "Creating temp directory /tmp/word_counter.root.20231017.090259.159612\n",
      "uploading working dir files to hdfs:///user/root/tmp/mrjob/word_counter.root.20231017.090259.159612/files/wd...\n",
      "Copying other local files to hdfs:///user/root/tmp/mrjob/word_counter.root.20231017.090259.159612/files/\n",
      "Running step 1 of 1...\n",
      "  packageJobJar: [/tmp/hadoop-unjar5348251561350976296/] [] /tmp/streamjob279501220240337468.jar tmpDir=null\n",
      "Attempting to fetch counters from logs...\n",
      "Can't fetch history log; missing job ID\n",
      "No counters found\n",
      "job output is in hdfs:///user/root/output\n",
      "Removing HDFS temp directory hdfs:///user/root/tmp/mrjob/word_counter.root.20231017.090259.159612...\n",
      "Removing temp directory /tmp/word_counter.root.20231017.090259.159612...\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Ejecución con fichero de entrada en HDFS y salida en HDFS\n",
    "# \n",
    "!hadoop fs -rm -r output\n",
    "!python3 word_counter.py -r hadoop hdfs:///user/root/input -o hdfs:///user/root/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a24d0279-a389-4ab3-98b0-af7344d25a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   1 root supergroup          0 2023-10-17 09:03 output/_SUCCESS\r\n",
      "-rw-r--r--   1 root supergroup       1742 2023-10-17 09:03 output/part-00000\r\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "090d49be-dc69-4c26-ba0c-a7677fd0de15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"a\"\t1\r\n",
      "\"about\"\t1\r\n",
      "\"aid\"\t1\r\n",
      "\"algorithms\"\t1\r\n",
      "\"analysis\"\t2\r\n",
      "\"analytics\"\t20\r\n",
      "\"analyze\"\t1\r\n",
      "\"and\"\t15\r\n",
      "\"application\"\t1\r\n",
      "\"apply\"\t1\r\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -cat output/part-00000 | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e97c8ec0-a9f3-4c52-9e6a-b7f8d6e0804a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted output\n",
      "Deleted tmp\n",
      "Deleted input\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -rm -r output\n",
    "!hadoop fs -rm -r tmp\n",
    "!hadoop fs -rm -r input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcd40f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
