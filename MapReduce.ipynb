{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "201d059c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sh: 0: getcwd() failed: No such file or directory\n",
      "/tmp/wordcount\n",
      "input\n"
     ]
    }
   ],
   "source": [
    "!rm -rf /tmp/wordcount\n",
    "!mkdir -p /tmp/wordcount/input\n",
    "%cd /tmp/wordcount\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2c6bf27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing input/text0.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile input/text0.txt\n",
    "Analytics is the discovery, interpretation, and communication of meaningful patterns\n",
    "in data. Especially valuable in areas rich with recorded information, analytics relies\n",
    "on the simultaneous application of statistics, computer programming and operations research\n",
    "to quantify performance.\n",
    "\n",
    "Organizations may apply analytics to business data to describe, predict, and improve business\n",
    "performance. Specifically, areas within analytics include predictive analytics, prescriptive\n",
    "analytics, enterprise decision management, descriptive analytics, cognitive analytics, Big\n",
    "Data Analytics, retail analytics, store assortment and stock-keeping unit optimization,\n",
    "marketing optimization and marketing mix modeling, web analytics, call analytics, speech\n",
    "analytics, sales force sizing and optimization, price and promotion modeling, predictive\n",
    "science, credit risk analysis, and fraud analytics. Since analytics can require extensive\n",
    "computation (see big data), the algorithms and software used for analytics harness the most\n",
    "current methods in computer science, statistics, and mathematics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "71782149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing input/text1.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile input/text1.txt\n",
    "The field of data analysis. Analytics often involves studying past historical data to\n",
    "research potential trends, to analyze the effects of certain decisions or events, or to\n",
    "evaluate the performance of a given tool or scenario. The goal of analytics is to improve\n",
    "the business by gaining knowledge which can be used to make improvements or changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07216bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing input/text2.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile input/text2.txt\n",
    "Data analytics (DA) is the process of examining data sets in order to draw conclusions\n",
    "about the information they contain, increasingly with the aid of specialized systems\n",
    "and software. Data analytics technologies and techniques are widely used in commercial\n",
    "industries to enable organizations to make more-informed business decisions and by\n",
    "scientists and researchers to verify or disprove scientific models, theories and\n",
    "hypotheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7fb2b065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python3\r\n"
     ]
    }
   ],
   "source": [
    "!which python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "564581a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "#! /usr/bin/python3\n",
    "\n",
    "import sys\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    for line in sys.stdin:\n",
    "        for word in line.split():\n",
    "            sys.stdout.write(\"{}\\t1\\n\".format(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c6df3131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer.py\n",
    "#! /usr/bin/python3\n",
    "\n",
    "import sys\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    curkey = None\n",
    "    total = 0\n",
    "\n",
    "    for line in sys.stdin:\n",
    "\n",
    "        key, val = line.split(\"\\t\")\n",
    "        val = int(val)\n",
    "\n",
    "        if key == curkey:\n",
    "            total += val\n",
    "        else:\n",
    "            if curkey is not None:\n",
    "                sys.stdout.write(\"{}\\t{}\\n\".format(curkey, total))\n",
    "\n",
    "            curkey = key\n",
    "            total = val\n",
    "\n",
    "    sys.stdout.write(\"{}\\t{}\\n\".format(curkey, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2344864a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/wordcount\n"
     ]
    }
   ],
   "source": [
    "%cd /tmp/wordcount\n",
    "!chmod +x mapper.py reducer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d8e14130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\r\n",
      "mapper.py\r\n",
      "reducer.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls  -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d5a53138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(DA)\t1\r\n",
      "(see\t1\r\n",
      "Analytics\t2\r\n",
      "Analytics,\t1\r\n",
      "Big\t1\r\n",
      "Data\t3\r\n",
      "Especially\t1\r\n",
      "Organizations\t1\r\n",
      "Since\t1\r\n",
      "Specifically,\t1\r\n"
     ]
    }
   ],
   "source": [
    "!cat input/text*.txt | python3 mapper.py | sort | python3 reducer.py | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ec4a42f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text0.txt\r\n",
      "text1.txt\r\n",
      "text2.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls -1 input/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "15477ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--   1 root supergroup       1082 2023-10-17 08:33 input/text0.txt\r\n",
      "-rw-r--r--   1 root supergroup        349 2023-10-17 08:33 input/text1.txt\r\n",
      "-rw-r--r--   1 root supergroup        435 2023-10-17 08:33 input/text2.txt\r\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -mkdir input\n",
    "!hadoop fs -copyFromLocal input/* input\n",
    "!hadoop fs -ls input/*\n",
    "#\n",
    "# Se puede usar la webUI para comprobar el sistema de ficheros, pestaña \"Utilities - Browse the file system\"\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "49dc27eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.sh\n",
    "#\n",
    "# Se ejecuta en Hadoop.\n",
    "#   -files: archivos a copiar al hdfs\n",
    "#   -input: archivo de entrada\n",
    "#   -output: directorio de salida\n",
    "#   -file: archivos a copiar de la maquina local al hdfs\n",
    "#   -mapper: programa que ejecuta el map\n",
    "#   -reducer: programa que ejecuta la reducción\n",
    "#\n",
    "hadoop fs -rm -r output\n",
    "\n",
    "hadoop jar \\\n",
    "    $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-*.jar \\\n",
    "    -files mapper.py,reducer.py  \\\n",
    "    -input input  \\\n",
    "    -output output \\\n",
    "    -mapper mapper.py \\\n",
    "    -reducer reducer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6154af1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `output': No such file or directory\n",
      "packageJobJar: [/tmp/hadoop-unjar4041784982998829825/] [] /tmp/streamjob8337579124133857454.jar tmpDir=null\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Lanzamos MapReduce\n",
    "#\n",
    "!bash app.sh\n",
    "#\n",
    "# Se pueden ver los procesos en la webUI de YARN\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3048d049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\r\n",
      "-rw-r--r--   1 root supergroup          0 2023-10-17 08:34 output/_SUCCESS\r\n",
      "-rw-r--r--   1 root supergroup       1649 2023-10-17 08:33 output/part-00000\r\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Contenido del directorio con los resultados de la ejecución\n",
    "#\n",
    "!hadoop fs -ls output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2b21f3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(DA)\t1\r\n",
      "(see\t1\r\n",
      "Analytics\t2\r\n",
      "Analytics,\t1\r\n",
      "Big\t1\r\n",
      "Data\t3\r\n",
      "Especially\t1\r\n",
      "Organizations\t1\r\n",
      "Since\t1\r\n",
      "Specifically,\t1\r\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Se visualiza el archivo con los resultados de la ejecución\n",
    "#\n",
    "!hadoop fs -cat output/part-00000 | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0dc259e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app_comb.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile app_comb.sh\n",
    "hadoop fs -rm -r output\n",
    "hadoop jar $HADOOP_HOME/share/hadoop/tools/lib/hadoop-streaming-*.jar \\\n",
    "   -files mapper.py,reducer.py \\\n",
    "   -input input \\\n",
    "   -output output  \\\n",
    "   -mapper mapper.py \\\n",
    "   -reducer reducer.py \\\n",
    "   -combiner reducer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c68d6ee1-f267-4af2-8969-bf9f01d9b897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted output\n",
      "packageJobJar: [/tmp/hadoop-unjar7209985952556640210/] [] /tmp/streamjob2902073394292491345.jar tmpDir=null\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# A diferencia del script anterior, en este caso se usa también una función \"combiner\" \n",
    "# cuyo código es el mismo de \"reducer\"\n",
    "#\n",
    "!bash app_comb.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "55b532d8-b805-455e-9b23-b3356a736a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(DA)\t1\r\n",
      "(see\t1\r\n",
      "Analytics\t2\r\n",
      "Analytics,\t1\r\n",
      "Big\t1\r\n",
      "Data\t3\r\n",
      "Especially\t1\r\n",
      "Organizations\t1\r\n",
      "Since\t1\r\n",
      "Specifically,\t1\r\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -cat output/part-00000 | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "94486268-bc13-4648-84dc-14e60a854700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted input\n",
      "Deleted output\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -rm -r -f -skipTrash input\n",
    "!hadoop fs -rm -r -f -skipTrash output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c013336",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
